{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGRU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-BExb9A_gIY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZG85Pfb06qK"
      },
      "source": [
        "from IPython.display import clear_output\r\n",
        "!pip install transformers\r\n",
        "!pip install datasets\r\n",
        "clear_output()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaB2Of7onSet"
      },
      "source": [
        "from transformers import AutoTokenizer\r\n",
        "from datasets import load_dataset"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90BTfOL_HDQ5"
      },
      "source": [
        "#Prepare model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY5CLLvZAIon"
      },
      "source": [
        "class TextGRU(nn.Module):\n",
        "    '''\n",
        "    Recurrent Neural Network based on Gated Rectified Unit for text classification [1].\n",
        "    Credits for implementation: [2]\n",
        "    Inputs:\n",
        "        vocab_size - size of vocabulary of dataset used\n",
        "        emb_dim - embedding space dimension\n",
        "        hidden_dim - dimension of hidden state of RNN\n",
        "        output_dim - dimension of the output (number of classes in our case)\n",
        "        dropout - drop out probability\n",
        "        pad_idx - padding index for sequences\n",
        "    [1]: Empirical evaluation of gated recurrent neural networks on sequence modeling, 2014.\n",
        "    [2]: https://github.com/etomoscow/DL-in-NLP/blob/master/hw3/task3_sentiment_rnn.ipynb\n",
        "    '''\n",
        "\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, out_dim, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, num_layers=1, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, out_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n",
        "        packed_output, hidden = self.rnn(packed_embedded)\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
        "        return self.fc(hidden)\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpzVWhc7HE6y"
      },
      "source": [
        "# Prepare dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-u6zQ3rbofz"
      },
      "source": [
        "#set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLdakYo3m2zQ",
        "outputId": "994114be-1102-4f33-f402-b41fc7f4ec62"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\r\n",
        "train_dataset = load_dataset('trec', split='train')\r\n",
        "train_dataset = train_dataset.map(\r\n",
        "    lambda e: tokenizer(e['text'], truncation=True, padding='max_length'),\r\n",
        "    batched=True\r\n",
        "    )\r\n",
        "test_dataset = load_dataset('trec', split='test')\r\n",
        "test_dataset = test_dataset.map(\r\n",
        "    lambda e: tokenizer(e['text'], truncation=True, padding='max_length'),\r\n",
        "    batched=True\r\n",
        "    )\r\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64)\r\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=64)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset trec (/root/.cache/huggingface/datasets/trec/default/1.1.0/1902c380fe66cc215f989888b1b35e8da7e79a3a97520f00dce753fd1f8f5c48)\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/trec/default/1.1.0/1902c380fe66cc215f989888b1b35e8da7e79a3a97520f00dce753fd1f8f5c48/cache-efaae888953b3ce0.arrow\n",
            "Using custom data configuration default\n",
            "Reusing dataset trec (/root/.cache/huggingface/datasets/trec/default/1.1.0/1902c380fe66cc215f989888b1b35e8da7e79a3a97520f00dce753fd1f8f5c48)\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/trec/default/1.1.0/1902c380fe66cc215f989888b1b35e8da7e79a3a97520f00dce753fd1f8f5c48/cache-3f3d932597ca390c.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPlHru5_KbRS"
      },
      "source": [
        "model = TextGRU(\r\n",
        "    vocab_size=tokenizer.vocab_size,\r\n",
        "    emb_dim=100,\r\n",
        "    hidden_dim=128,\r\n",
        "    out_dim=6,\r\n",
        "    dropout=0.1,\r\n",
        "    pad_idx=tokenizer.pad_token_id)\r\n",
        "\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAlRpJk8L-BM"
      },
      "source": [
        "def trec_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim=1, keepdim=True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    correct = correct.detach().to('cpu')\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQRLKIOpgggm"
      },
      "source": [
        "def get_text_length(batch, tokenizer):\n",
        "    result = []\n",
        "    for i in range(batch.shape[1]):\n",
        "        result.append((sum(batch[:, i] != tokenizer.pad_token_id).item()))\n",
        "    return torch.tensor(result, dtype=int, device='cpu')"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMu9EVvA0kG8",
        "outputId": "9348389b-ea95-4b84-9abd-4abc25df3704"
      },
      "source": [
        "get_text_length(torch.stack(x['input_ids'], dim=0), tokenizer)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([14, 11, 14, 17, 11, 15, 14,  8,  7, 14, 10, 10, 10,  6, 16, 14, 18, 13,\n",
              "        12, 10, 10, 12,  7,  9, 13, 15, 11, 12, 10, 11, 10, 10, 14, 19, 12,  8,\n",
              "        11, 11, 18, 18, 13, 17, 11, 14, 13, 12, 18, 10, 14, 13, 13,  8, 11, 15,\n",
              "        12,  9, 14, 12, 13,  8,  7, 21, 10,  6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5nAT8OsMFgi"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, tokenizer):\n",
        "    global device\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        batch_ = torch.stack(batch['input_ids'], dim=0)\n",
        "        batch_ = batch_.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        text_lengths = get_text_length(batch_, tokenizer) \n",
        "        predictions = model(batch_, text_lengths)\n",
        "        loss = criterion(predictions, batch['label-coarse'].long().to(device))\n",
        "        acc = trec_accuracy(predictions, batch['label-coarse'].to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1NcO2waMMnJ"
      },
      "source": [
        "def evaluate(model, iterator, criterion, tokenizer):\n",
        "    global device\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            batch_ = torch.stack(batch['input_ids'], dim=0)\n",
        "            batch_ = batch_.to(device)\n",
        "            text_lengths = get_text_length(batch_, tokenizer)\n",
        "            predictions = model(batch_, text_lengths)\n",
        "            loss = criterion(predictions, batch['label-coarse'].long().to(device))\n",
        "            acc = trec_accuracy(predictions, batch['label-coarse'].to(device))\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7jCjQKeMRAm"
      },
      "source": [
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpN418NeMTHN",
        "outputId": "e737b304-1773-40ac-9045-99f1474d4a3b"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "best_valid_loss = float('inf')\n",
        "losses = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(model, trainloader, optimizer, criterion, tokenizer)\n",
        "    valid_loss, valid_acc = evaluate(model, testloader, criterion, tokenizer)\n",
        "    losses.append(train_loss)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'textrnn_trec.pt')\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    if epoch >= 3:\n",
        "        if train_loss >= losses[-1] and train_loss >= losses[-2] and train_loss >= losses[-3]:\n",
        "            print('Early stopping')\n",
        "            break "
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 38s\n",
            "\tTrain Loss: 1.182 | Train Acc: 53.94%\n",
            "\t Val. Loss: 0.820 |  Val. Acc: 72.94%\n",
            "Epoch: 02 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.744 | Train Acc: 71.92%\n",
            "\t Val. Loss: 0.626 |  Val. Acc: 77.19%\n",
            "Epoch: 03 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.541 | Train Acc: 80.47%\n",
            "\t Val. Loss: 0.596 |  Val. Acc: 78.67%\n",
            "Epoch: 04 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.387 | Train Acc: 86.70%\n",
            "\t Val. Loss: 0.616 |  Val. Acc: 77.94%\n",
            "Epoch: 05 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 0.274 | Train Acc: 91.09%\n",
            "\t Val. Loss: 0.714 |  Val. Acc: 79.45%\n",
            "Epoch: 06 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 0.182 | Train Acc: 94.04%\n",
            "\t Val. Loss: 0.849 |  Val. Acc: 78.03%\n",
            "Epoch: 07 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.123 | Train Acc: 96.26%\n",
            "\t Val. Loss: 0.807 |  Val. Acc: 79.64%\n",
            "Epoch: 08 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.080 | Train Acc: 97.33%\n",
            "\t Val. Loss: 0.672 |  Val. Acc: 82.42%\n",
            "Epoch: 09 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.052 | Train Acc: 98.62%\n",
            "\t Val. Loss: 0.730 |  Val. Acc: 82.68%\n",
            "Epoch: 10 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 0.034 | Train Acc: 99.09%\n",
            "\t Val. Loss: 0.790 |  Val. Acc: 82.72%\n",
            "Epoch: 11 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.030 | Train Acc: 99.16%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 83.64%\n",
            "Epoch: 12 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.028 | Train Acc: 99.16%\n",
            "\t Val. Loss: 0.781 |  Val. Acc: 82.77%\n",
            "Epoch: 13 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.27%\n",
            "\t Val. Loss: 0.783 |  Val. Acc: 84.60%\n",
            "Epoch: 14 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.013 | Train Acc: 99.71%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 86.27%\n",
            "Epoch: 15 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.010 | Train Acc: 99.75%\n",
            "\t Val. Loss: 0.738 |  Val. Acc: 83.10%\n",
            "Epoch: 16 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.010 | Train Acc: 99.82%\n",
            "\t Val. Loss: 0.764 |  Val. Acc: 84.03%\n",
            "Epoch: 17 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.005 | Train Acc: 99.89%\n",
            "\t Val. Loss: 0.758 |  Val. Acc: 85.05%\n",
            "Epoch: 18 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.004 | Train Acc: 99.96%\n",
            "\t Val. Loss: 0.757 |  Val. Acc: 85.01%\n",
            "Epoch: 19 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.003 | Train Acc: 99.96%\n",
            "\t Val. Loss: 0.799 |  Val. Acc: 85.25%\n",
            "Epoch: 20 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.007 | Train Acc: 99.80%\n",
            "\t Val. Loss: 0.764 |  Val. Acc: 86.31%\n",
            "Early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSi92JYoaUdD",
        "outputId": "b3d6b002-c953-4c84-c926-3da3b287a4b2"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextGRU(\n",
              "  (embedding): Embedding(30522, 100, padding_idx=0)\n",
              "  (rnn): GRU(100, 128, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMI7w2w57_J-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
