{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_lev dataset forming.ipynb\"\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4095f8779e2549a2ad64941bc44f97a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6bfb63329f17463abe08e0c386ba6528",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c93182f5d168450781bd37c886583177",
              "IPY_MODEL_15151e65ca0341389afd416d4bebeda8"
            ]
          }
        },
        "6bfb63329f17463abe08e0c386ba6528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c93182f5d168450781bd37c886583177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8d0d4afac6fc414382a13092209df131",
            "_dom_classes": [],
            "description": " 38%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4c90722ab324a04899f27eab455eaa3"
          }
        },
        "15151e65ca0341389afd416d4bebeda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5bea209abb954898ba8ebacb149ace64",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6/16 [00:06&lt;00:10,  1.07s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa7a956c3a5c46eb9910ecad7620c5ca"
          }
        },
        "8d0d4afac6fc414382a13092209df131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4c90722ab324a04899f27eab455eaa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bea209abb954898ba8ebacb149ace64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa7a956c3a5c46eb9910ecad7620c5ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2431450b438046c897f1d5cfc38fc7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aa596e95fb9c4c21aa54a01588062b14",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e522b4a8b9247fcafc21da897f6594b",
              "IPY_MODEL_c591dba1eac34498a492c3a6c700e990"
            ]
          }
        },
        "aa596e95fb9c4c21aa54a01588062b14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e522b4a8b9247fcafc21da897f6594b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_40ab70fad0d24df4acf9859e09cc1459",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 30000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 30000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4c8ad7f9df74bf98db9785251175bb2"
          }
        },
        "c591dba1eac34498a492c3a6c700e990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_853ab7436d2547f6b16f2878cff221d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30000/30000 [00:00&lt;00:00, 72102.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1590be50efb4da48d1d27ac6f10e659"
          }
        },
        "40ab70fad0d24df4acf9859e09cc1459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4c8ad7f9df74bf98db9785251175bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "853ab7436d2547f6b16f2878cff221d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1590be50efb4da48d1d27ac6f10e659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44b81c25287d49b1b60716940c2768df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac307b85269242b49d186adb37964f37",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b8a8618ae54419a9b1f0d36a68f5768",
              "IPY_MODEL_dc9356f02a4347c0bd86011e806cac87"
            ]
          }
        },
        "ac307b85269242b49d186adb37964f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b8a8618ae54419a9b1f0d36a68f5768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1bfef5c49be94db796b8c86e7533d9b6",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b19e1cbf3494ed7b0cb1f70fd4e0a9b"
          }
        },
        "dc9356f02a4347c0bd86011e806cac87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf6530677ed2434a8734b2b1cf89f2e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1200/1200 [00:00&lt;00:00, 4581.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59ddcc27f39f4574890fe3d6a1c28f3b"
          }
        },
        "1bfef5c49be94db796b8c86e7533d9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b19e1cbf3494ed7b0cb1f70fd4e0a9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf6530677ed2434a8734b2b1cf89f2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59ddcc27f39f4574890fe3d6a1c28f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBy8duiBbqRD",
        "outputId": "f16b8d74-6d81-4156-e031-64ce4fabab5d"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbpLXh2xb5lh"
      },
      "source": [
        "from tqdm.notebook import tqdm\r\n",
        "import torch\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torch.nn as nn"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vytrcjkyrFoY",
        "outputId": "62e4872e-e5b0-4602-d6cf-a8a758311763"
      },
      "source": [
        "!pip install jsonlines\r\n",
        "import jsonlines\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "!pip install python-levenshtein\r\n",
        "import Levenshtein as Lev\r\n",
        "import torch\r\n",
        "from torch.utils.data import Dataset as TorchDataset\r\n",
        "from typing import Sequence, Dict, Any, List\r\n",
        "import json"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.15.0)\n",
            "Requirement already satisfied: python-levenshtein in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein) (50.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIDSfNJtcQtR"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo2SrllPt1Hg",
        "outputId": "307e068d-922f-47d4-d1ae-b33563fdf93e"
      },
      "source": [
        "!pip install datasets\r\n",
        "from datasets import load_dataset\r\n",
        "dataset = load_dataset('trec')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.6/dist-packages (1.1.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset trec (/root/.cache/huggingface/datasets/trec/default/1.1.0/1902c380fe66cc215f989888b1b35e8da7e79a3a97520f00dce753fd1f8f5c48)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skIzzbqGjm6G"
      },
      "source": [
        "## **We use pre-trained MLM: Bert for masked LM from the huggingface transformers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6lE0q8dCjRx"
      },
      "source": [
        "from transformers import BertTokenizerFast, BertForMaskedLM\r\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T0M892DD3Te",
        "outputId": "684d3430-4809-400b-cf20-d3bed30768d3"
      },
      "source": [
        "from transformers import AutoTokenizer\r\n",
        "dataset = load_dataset('trec', split='test')\r\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\r\n",
        "dataset = dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length'), batched=True)\r\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset trec (/root/.cache/huggingface/datasets/trec/default/1.1.0/1902c380fe66cc215f989888b1b35e8da7e79a3a97520f00dce753fd1f8f5c48)\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/trec/default/1.1.0/1902c380fe66cc215f989888b1b35e8da7e79a3a97520f00dce753fd1f8f5c48/cache-1bec60d6e272bbd1.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngSYxCkDU2HF",
        "outputId": "c739ba53-c3e3-4cb4-e997-7d7f1336eba1"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['attention_mask', 'input_ids', 'label-coarse', 'label-fine', 'text', 'token_type_ids'],\n",
              "    num_rows: 500\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZE4b9KwFRtM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a1b335-a18e-4f2c-c56d-4b3b46b959a6"
      },
      "source": [
        "dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label-coarse'])\r\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)\r\n",
        "next(iter(dataloader))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " 'input_ids': tensor([[  101,  2129,  2521,  ...,     0,     0,     0],\n",
              "         [  101,  2054,  2221,  ...,     0,     0,     0],\n",
              "         [  101,  2040,  2001,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  2054, 14130,  ...,     0,     0,     0],\n",
              "         [  101,  2054,  2003,  ...,     0,     0,     0],\n",
              "         [  101,  2073,  2024,  ...,     0,     0,     0]]),\n",
              " 'label-coarse': tensor([4, 5, 3, 0, 4, 4, 3, 1, 0, 0, 5, 3, 4, 3, 4, 4, 1, 3, 0, 4, 3, 0, 5, 0,\n",
              "         0, 3, 0, 5, 5, 5, 4, 5]),\n",
              " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5mYYeIBGLxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3404c2bd-082d-467c-8069-8cac4a8f763c"
      },
      "source": [
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased').to(device)\r\n",
        "model.eval()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaRj6SBMIP97"
      },
      "source": [
        "import numpy as np\r\n",
        "import random \r\n",
        "\r\n",
        "def mask_tokens(batch, tokenizer):\r\n",
        "    batch_masked, masked_inds = [], []\r\n",
        "    for b in batch:\r\n",
        "        inds_to_mask = np.random.choice(torch.arange(1, (b[b!=0].shape[0] -1)), size=1)\r\n",
        "        masked_inds.append(inds_to_mask)\r\n",
        "        b_new = b.clone()\r\n",
        "        b_new[inds_to_mask] = tokenizer.mask_token_id\r\n",
        "        batch_masked.append(b_new)\r\n",
        "    return torch.stack(batch_masked), masked_inds"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubLIUnFCMN0o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4095f8779e2549a2ad64941bc44f97a8",
            "6bfb63329f17463abe08e0c386ba6528",
            "c93182f5d168450781bd37c886583177",
            "15151e65ca0341389afd416d4bebeda8",
            "8d0d4afac6fc414382a13092209df131",
            "a4c90722ab324a04899f27eab455eaa3",
            "5bea209abb954898ba8ebacb149ace64",
            "aa7a956c3a5c46eb9910ecad7620c5ca"
          ]
        },
        "outputId": "d8175a7d-0c7f-4e52-9582-8ffb7e851f98"
      },
      "source": [
        "all_logits = []\r\n",
        "all_input = []\r\n",
        "all_attent_masks = []\r\n",
        "counter = 0\r\n",
        "for batch in tqdm(dataloader):\r\n",
        "    with torch.no_grad():\r\n",
        "        if counter < 6:\r\n",
        "            b_input_ids = batch['input_ids']\r\n",
        "            b_input_mask = batch['attention_mask'].to(device)\r\n",
        "\r\n",
        "            b_masked, masked_inds = mask_tokens(b_input_ids, tokenizer)\r\n",
        "            logits = model(b_masked.to(device), attention_mask=b_input_mask)\r\n",
        "            all_logits.append(logits[0])\r\n",
        "            all_attent_masks.append(b_input_mask)\r\n",
        "            all_input.append(b_input_ids)\r\n",
        "            counter = counter + 1\r\n",
        "        else:\r\n",
        "            break\r\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4095f8779e2549a2ad64941bc44f97a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOS9KNl84hYI"
      },
      "source": [
        "generated_batch_sentence = []\r\n",
        "original_batch_sentence = []\r\n",
        "for logits, inputs, attention_mask in zip(all_logits, all_input, all_attent_masks):\r\n",
        "    for i in range(32):\r\n",
        "        generated = (torch.argmax(torch.softmax(logits[i], axis=1), axis=1) * attention_mask[i])\r\n",
        "        original = inputs[i]\r\n",
        "        original_batch_sentence.append(tokenizer.decode(original[(original!=0) & (original!=101) & (original!=102)]))\r\n",
        "        generated_batch_sentence.append(tokenizer.decode(generated[(generated != 0) & (generated!=1012)]))\r\n",
        "        \r\n",
        "sentences = generated_batch_sentence + original_batch_sentence"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q96P0ae8vwf",
        "outputId": "beecdba8-b3cc-43c6-d433-4d0bae1ebec8"
      },
      "source": [
        "for i in range(32):\r\n",
        "    generated = (torch.argmax(torch.softmax(all_logits[0][i], axis=1), axis=1) * all_attent_masks[0][i])\r\n",
        "    original = all_input[0][i]\r\n",
        "    print('Original:')\r\n",
        "    print(tokenizer.decode(original[(original!=0) & (original!=101) & (original!=102)]))\r\n",
        "    print('Generated:')\r\n",
        "    print(tokenizer.decode(generated[(generated != 0) & (generated!=1012)]))\r\n",
        "    print('-'*40)\r\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:\n",
            "how far is it from denver to aspen?\n",
            "Generated:\n",
            "how far is it from denver to aspen?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what county is modesto, california in?\n",
            "Generated:\n",
            "what county is modesto, california in?\n",
            "----------------------------------------\n",
            "Original:\n",
            "who was galileo?\n",
            "Generated:\n",
            "who was galileo?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is an atom?\n",
            "Generated:\n",
            "what is an atom?\n",
            "----------------------------------------\n",
            "Original:\n",
            "when did hawaii become a state?\n",
            "Generated:\n",
            "when did hawaii become a state?\n",
            "----------------------------------------\n",
            "Original:\n",
            "how tall is the sears building?\n",
            "Generated:\n",
            "how tall is the apartment building?\n",
            "----------------------------------------\n",
            "Original:\n",
            "george bush purchased a small interest in which baseball team?\n",
            "Generated:\n",
            "george bush purchased a small interest in the baseball team\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is australia's national flower?\n",
            "Generated:\n",
            "what is australia's national flower?\n",
            "----------------------------------------\n",
            "Original:\n",
            "why does the moon turn orange?\n",
            "Generated:\n",
            "why does the moon turn orange?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is autism?\n",
            "Generated:\n",
            "what is autism?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what city had a world fair in 1900?\n",
            "Generated:\n",
            "which city had a world fair in 1900?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what person's head is on a dime?\n",
            "Generated:\n",
            "what person's head is on a dime?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is the average weight of a yellow labrador?\n",
            "Generated:\n",
            "what is the average weight of a yellow labrador?\n",
            "----------------------------------------\n",
            "Original:\n",
            "who was the first man to fly across the pacific ocean?\n",
            "Generated:\n",
            "who was the first woman to fly across the pacific ocean?\n",
            "----------------------------------------\n",
            "Original:\n",
            "when did idaho become a state?\n",
            "Generated:\n",
            "when did idaho become a state?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is the life expectancy for crickets?\n",
            "Generated:\n",
            "what is the life expectancy for crickets?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what metal has the highest melting point?\n",
            "Generated:\n",
            "what metal has the highest melting point?\n",
            "----------------------------------------\n",
            "Original:\n",
            "who developed the vaccination against polio?\n",
            "Generated:\n",
            "who developed the vaccination against polio?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is epilepsy?\n",
            "Generated:\n",
            "what is epilepsy?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what year did the titanic sink?\n",
            "Generated:\n",
            "what year did the titanic sink?\n",
            "----------------------------------------\n",
            "Original:\n",
            "who was the first american to walk in space?\n",
            "Generated:\n",
            "who was the first person to walk in space?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is a biosphere?\n",
            "Generated:\n",
            "what is a biosphere?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what river in the us is known as the big muddy?\n",
            "Generated:\n",
            "what river in the us is known as the big river?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is bipolar disorder?\n",
            "Generated:\n",
            "what is this disorder?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is cholesterol?\n",
            "Generated:\n",
            "what is cholesterol?\n",
            "----------------------------------------\n",
            "Original:\n",
            "who developed the macintosh computer?\n",
            "Generated:\n",
            "who developed the macintosh software?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is caffeine?\n",
            "Generated:\n",
            "what about caffe coffee?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what imaginary line is halfway between the north and south poles?\n",
            "Generated:\n",
            "what imaginary line is halfway between the north and south poles?\n",
            "----------------------------------------\n",
            "Original:\n",
            "where is john wayne airport?\n",
            "Generated:\n",
            "where is john wayne airport?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what hemisphere is the philippines in?\n",
            "Generated:\n",
            "what hemisphere is the philippines in?\n",
            "----------------------------------------\n",
            "Original:\n",
            "what is the average speed of the horses at the kentucky derby?\n",
            "Generated:\n",
            "what is the average speed of the horses at the kentucky derby?\n",
            "----------------------------------------\n",
            "Original:\n",
            "where are the rocky mountains?\n",
            "Generated:\n",
            "where are the rocky mountains?\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5XSVYRI7J2Q"
      },
      "source": [
        "def calculate_wer(sequence_a: str, sequence_b: str) -> int:\r\n",
        "    # taken from https://github.com/SeanNaren/deepspeech.pytorch/blob/master/decoder.py\r\n",
        "    b = set(sequence_a.split() + sequence_b.split())\r\n",
        "    word2char = dict(zip(b, range(len(b))))\r\n",
        "\r\n",
        "    w1 = [chr(word2char[w]) for w in sequence_a.split()]\r\n",
        "    w2 = [chr(word2char[w]) for w in sequence_b.split()]\r\n",
        "\r\n",
        "    return Lev.distance(''.join(w1), ''.join(w2))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8zsxBfwra9d"
      },
      "source": [
        "class SequenceModifier:\r\n",
        "    # taken from https://github.com/fursovia/dilma/blob/ef582e73a1cfce5f6bd753fb08b588f12f5cde8f/adat/utils.py#L103\r\n",
        "    def __init__(\r\n",
        "            self,\r\n",
        "            vocab: List[str],\r\n",
        "            remove_prob: float = 0.05,\r\n",
        "            add_prob: float = 0.05,\r\n",
        "            replace_prob: float = 0.1\r\n",
        "    ) -> None:\r\n",
        "        assert sum([remove_prob, add_prob, replace_prob]) > 0.0\r\n",
        "        self.vocab = vocab\r\n",
        "        self.remove_prob = remove_prob\r\n",
        "        self.add_prob = add_prob\r\n",
        "        self.replace_prob = replace_prob\r\n",
        "\r\n",
        "    def remove_token(self, sequence: List[str]) -> List[str]:\r\n",
        "        samples = np.random.binomial(n=1, p=self.remove_prob, size=len(sequence))\r\n",
        "        sequence = [token for i, token in enumerate(sequence) if not samples[i]]\r\n",
        "        return sequence\r\n",
        "\r\n",
        "    def replace_token(self, sequence: List[str]) -> List[str]:\r\n",
        "        samples = np.random.binomial(n=1, p=self.replace_prob, size=len(sequence))\r\n",
        "        new_sequence = [random.choice(self.vocab) if samples[i] else sequence[i] for i in range(len(sequence))]\r\n",
        "        return new_sequence\r\n",
        "\r\n",
        "    def add_token(self, sequence: List[str]) -> List[str]:\r\n",
        "        new_sequence = sequence + [\r\n",
        "            random.choice(self.vocab)\r\n",
        "            for _ in range(np.random.binomial(len(sequence), self.add_prob))\r\n",
        "        ]\r\n",
        "        return new_sequence\r\n",
        "\r\n",
        "    def __call__(self, sequence: str) -> str:\r\n",
        "        splitted_sequence = sequence.split()\r\n",
        "        if len(splitted_sequence) > 1 and self.remove_prob:\r\n",
        "            splitted_sequence = self.remove_token(splitted_sequence)\r\n",
        "\r\n",
        "        if self.replace_prob:\r\n",
        "            splitted_sequence = self.replace_token(splitted_sequence)\r\n",
        "\r\n",
        "        if self.add_prob:\r\n",
        "            splitted_sequence = self.add_token(splitted_sequence)\r\n",
        "        return \" \".join(splitted_sequence)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2431450b438046c897f1d5cfc38fc7d5",
            "aa596e95fb9c4c21aa54a01588062b14",
            "4e522b4a8b9247fcafc21da897f6594b",
            "c591dba1eac34498a492c3a6c700e990",
            "40ab70fad0d24df4acf9859e09cc1459",
            "c4c8ad7f9df74bf98db9785251175bb2",
            "853ab7436d2547f6b16f2878cff221d4",
            "a1590be50efb4da48d1d27ac6f10e659"
          ]
        },
        "id": "ZN6kDSvo4gEk",
        "outputId": "3c08e8f5-2adf-442b-be75-ae3d23fcd3f8"
      },
      "source": [
        "dataset_dl = []\r\n",
        "non_adversarial_indexes = np.random.randint(0, len(sentences), size=(30000, 2))\r\n",
        "for id1, id2 in tqdm(non_adversarial_indexes):\r\n",
        "    tr1 = sentences[id1].strip()\r\n",
        "    tr2 = sentences[id2].strip()\r\n",
        "    \r\n",
        "    dist = calculate_wer(tr1, tr2)\r\n",
        "    ex = {\"seq_a\": tr1, \"seq_b\": tr2, \"dist\": dist}\r\n",
        "    dataset_dl.append(ex)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2431450b438046c897f1d5cfc38fc7d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=30000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy8XRCan0PTs",
        "outputId": "a71dc0bf-5478-4486-f96d-dc5457e8aa9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXCIJmolJ8_H",
        "outputId": "17597f1b-2650-4fee-8fc5-03070747d841"
      },
      "source": [
        "len(dataset_dl)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "44b81c25287d49b1b60716940c2768df",
            "ac307b85269242b49d186adb37964f37",
            "1b8a8618ae54419a9b1f0d36a68f5768",
            "dc9356f02a4347c0bd86011e806cac87",
            "1bfef5c49be94db796b8c86e7533d9b6",
            "7b19e1cbf3494ed7b0cb1f70fd4e0a9b",
            "cf6530677ed2434a8734b2b1cf89f2e0",
            "59ddcc27f39f4574890fe3d6a1c28f3b"
          ]
        },
        "id": "IfCR4CRhGhoH",
        "outputId": "8b2b7397-5f44-4614-90a0-aa5f3c432502"
      },
      "source": [
        "vocab = []\r\n",
        "for seq in sentences:\r\n",
        "    vocab.extend(seq.split())\r\n",
        "\r\n",
        "vocab = list(set(vocab))\r\n",
        "NUM_SMALL_CHANGES = 2\r\n",
        "NUM_SEQUENTIAL_CHANGES = 8\r\n",
        "\r\n",
        "REMOVE_PROB = 0.0\r\n",
        "ADD_PROB = 0.0\r\n",
        "REPLACE_PROB = 1.0\r\n",
        "\r\n",
        "modifier = SequenceModifier(\r\n",
        "    vocab,\r\n",
        "    remove_prob = REMOVE_PROB,\r\n",
        "    add_prob = ADD_PROB,\r\n",
        "    replace_prob = REPLACE_PROB\r\n",
        ")\r\n",
        "adversarial_indexes = np.random.randint(0, len(sentences), size=(1200, ))\r\n",
        "for idx in tqdm(adversarial_indexes):\r\n",
        "    tr1 = sentences[idx].strip()\r\n",
        "\r\n",
        "    for _ in range(NUM_SMALL_CHANGES):\r\n",
        "        tr2 = modifier(tr1).strip()\r\n",
        "        dist = calculate_wer(tr1, tr2)\r\n",
        "        ex = {\"seq_a\": tr1, \"seq_b\": tr2, \"dist\": dist}\r\n",
        "        dataset_dl.append(ex)\r\n",
        "\r\n",
        "    tr2 = tr1\r\n",
        "    num_changes = NUM_SEQUENTIAL_CHANGES\r\n",
        "    if num_changes > len(tr1.split()):\r\n",
        "        num_changes = len(tr1.split())\r\n",
        "    for _ in range(num_changes):\r\n",
        "        position_idx = random.randint(0, len(tr1.split()) - 1)\r\n",
        "        replace_with = random.choice(vocab)\r\n",
        "        tr2 = tr2.split()\r\n",
        "        tr2[position_idx] = replace_with\r\n",
        "        tr2 = \" \".join(tr2)\r\n",
        "\r\n",
        "        dist = calculate_wer(tr1, tr2)\r\n",
        "        ex = {\"seq_a\": tr1, \"seq_b\": tr2, \"dist\": dist}\r\n",
        "        dataset_dl.append(ex)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44b81c25287d49b1b60716940c2768df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1200.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oomI0eTgL8F1",
        "outputId": "64a06152-a000-4282-aec9-1afcb64750c3"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9ulyPskLibE"
      },
      "source": [
        "train_path = \"/content/gdrive/My Drive/train_dl.json\"\r\n",
        "test_path = \"/content/gdrive/My Drive/test_dl.json\""
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s6dhO_XgQfO"
      },
      "source": [
        "train, test = train_test_split(dataset_dl, test_size = 0.33, random_state = 42, shuffle = True)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7chuMOuEtgOX",
        "outputId": "b51265a8-aa43-442c-f204-1352cef944d1"
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26422"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n19aiERdhYOB"
      },
      "source": [
        "with jsonlines.open(train_path, \"w\") as writer:\r\n",
        "    for ex in train:\r\n",
        "        writer.write(ex)\r\n",
        "\r\n",
        "with jsonlines.open(test_path, \"w\") as writer:\r\n",
        "    for ex in test:\r\n",
        "        writer.write(ex)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5HRpZgl1bn6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}